{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnijMYzADB1E6ZzxFSSyee",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charchar1245/Transformer-for-Translating-English-to-Spanish/blob/main/dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "id": "G2Mtx2RCt6jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKjYwofds4ww",
        "outputId": "ee8f4a3a-a287-4871-be82-ac7054e99e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Import dataset from Huggingface\n",
        "ds = load_dataset(\"okezieowen/english_to_spanish\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For testing purposes in this file, we will just take the first 10 sentences from the data\n",
        "selected_data = ds['train'].select(range(10))\n",
        "df = selected_data.to_pandas()"
      ],
      "metadata": {
        "id": "5JUt1ZuHs_ri"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "# Tokenize text\n",
        "def tokenize(text, language):\n",
        "  if language == 'en':\n",
        "    spacy_en = spacy.load(\"en_core_web_sm\")\n",
        "    return [token.text for token in spacy_en.tokenizer(text)]\n",
        "  elif language == 'es':\n",
        "    spacy_es = spacy.load(\"es_core_news_sm\")\n",
        "  return [token.text for token in spacy_es.tokenizer(text)]\n",
        "\n",
        "\n",
        "# New variable for tokenized text\n",
        "all_tokens_english = [tokenize(sentence, 'en') for sentence in df['English'] if sentence is not None]\n",
        "\n",
        "all_tokens_spanish = [tokenize(sentence, 'es') for sentence in df['Spanish'] if sentence is not None]\n"
      ],
      "metadata": {
        "id": "hsZjtzdzujON"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tokens in all_tokens_spanish:\n",
        "  print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6FHs_Ny63yB",
        "outputId": "b6aca0ae-0ffd-4ee4-c67a-e6103f011229"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Declaro', 'reanudado', 'el', 'período', 'de', 'sesiones', 'del', 'Parlamento', 'Europeo', ',', 'interrumpido', 'el', 'viernes', '17', 'de', 'diciembre', 'pasado', ',', 'y', 'reitero', 'a', 'Sus', 'Señorías', 'mi', 'deseo', 'de', 'que', 'hayan', 'tenido', 'unas', 'buenas', 'vacaciones', '.']\n",
            "['Como', 'todos', 'han', 'podido', 'comprobar', ',', 'el', 'gran', '\"', 'efecto', 'del', 'año', '2000', '\"', 'no', 'se', 'ha', 'producido', '.', 'En', 'cambio', ',', 'los', 'ciudadanos', 'de', 'varios', 'de', 'nuestros', 'países', 'han', 'sido', 'víctimas', 'de', 'catástrofes', 'naturales', 'verdaderamente', 'terribles', '.']\n",
            "['Sus', 'Señorías', 'han', 'solicitado', 'un', 'debate', 'sobre', 'el', 'tema', 'para', 'los', 'próximos', 'días', ',', 'en', 'el', 'curso', 'de', 'este', 'período', 'de', 'sesiones', '.']\n",
            "['A', 'la', 'espera', 'de', 'que', 'se', 'produzca', ',', 'de', 'acuerdo', 'con', 'muchos', 'colegas', 'que', 'me', 'lo', 'han', 'pedido', ',', 'pido', 'que', 'hagamos', 'un', 'minuto', 'de', 'silencio', 'en', 'memoria', 'de', 'todas', 'las', 'víctimas', 'de', 'las', 'tormentas', ',', 'en', 'los', 'distintos', 'países', 'de', 'la', 'Unión', 'Europea', 'afectados', '.']\n",
            "['Invito', 'a', 'todos', 'a', 'que', 'nos', 'pongamos', 'de', 'pie', 'para', 'guardar', 'un', 'minuto', 'de', 'silencio', '.']\n",
            "['(', 'El', 'Parlamento', ',', 'de', 'pie', ',', 'guarda', 'un', 'minuto', 'de', 'silencio', ')']\n",
            "['Señora', 'Presidenta', ',', 'una', 'cuestión', 'de', 'procedimiento', '.']\n",
            "['Sabrá', 'usted', 'por', 'la', 'prensa', 'y', 'la', 'televisión', 'que', 'se', 'han', 'producido', 'una', 'serie', 'de', 'explosiones', 'y', 'asesinatos', 'en', 'Sri', 'Lanka', '.']\n",
            "['Una', 'de', 'las', 'personas', 'que', 'recientemente', 'han', 'asesinado', 'en', 'Sri', 'Lanka', 'ha', 'sido', 'al', 'Sr.', 'Kumar', 'Ponnambalam', ',', 'quien', 'hace', 'pocos', 'meses', 'visitó', 'el', 'Parlamento', 'Europeo', '.']\n",
            "['¿', 'Sería', 'apropiado', 'que', 'usted', ',', 'Señora', 'Presidenta', ',', 'escribiese', 'una', 'carta', 'al', 'Presidente', 'de', 'Sri', 'Lanka', 'expresando', 'las', 'condolencias', 'del', 'Parlamento', 'por', 'esa', 'y', 'otras', 'muertes', 'violentas', ',', 'pidiéndole', 'que', 'haga', 'todo', 'lo', 'posible', 'para', 'encontrar', 'una', 'reconciliación', 'pacífica', 'ante', 'la', 'extremadamente', 'difícil', 'situación', 'que', 'está', 'viviendo', 'su', 'país', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchtext\n",
        "!pip install torch==2.2.2 torchtext==0.17.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xu1AwyK87FFR",
        "outputId": "ce0c3150-5c6f-4fad-a073-f10dbceb0ef9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.2.2\n",
            "Uninstalling torch-2.2.2:\n",
            "  Successfully uninstalled torch-2.2.2\n",
            "Found existing installation: torchtext 0.17.2\n",
            "Uninstalling torchtext-0.17.2:\n",
            "  Successfully uninstalled torchtext-0.17.2\n",
            "'import warnings' failed; traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/warnings.py\", line 587, in <module>\n",
            "    _processoptions(sys.warnoptions)\n",
            "  File \"/usr/lib/python3.12/warnings.py\", line 211, in _processoptions\n",
            "    _setoption(arg)\n",
            "  File \"/usr/lib/python3.12/warnings.py\", line 227, in _setoption\n",
            "    import re\n",
            "  File \"/usr/lib/python3.12/re/__init__.py\", line 125, in <module>\n",
            "    from . import _compiler, _parser\n",
            "  File \"/usr/lib/python3.12/re/_compiler.py\", line 14, in <module>\n",
            "    from . import _parser\n",
            "  File \"/usr/lib/python3.12/re/_parser.py\", line 111, in <module>\n",
            "    class SubPattern:\n",
            "KeyboardInterrupt\n",
            "Collecting torch==2.2.2\n",
            "  Using cached torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchtext==0.17.2\n",
            "  Using cached torchtext-0.17.2-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.17.2) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.17.2) (2.32.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext==0.17.2) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2) (12.9.86)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.2.2) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.17.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.17.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.17.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.17.2) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.2) (1.3.0)\n",
            "Using cached torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl (755.5 MB)\n",
            "Using cached torchtext-0.17.2-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "Installing collected packages: torch, torchtext\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cpu requires torch==2.9.0, but you have torch 2.2.2 which is incompatible.\n",
            "torchvision 0.24.0+cpu requires torch==2.9.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.2.2 torchtext-0.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "torchtext"
                ]
              },
              "id": "3dbe0d5992f24dfb8248d2f643ee1ae6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "vocab_english = build_vocab_from_iterator(\n",
        "    all_tokens_english,\n",
        "    min_freq=1,\n",
        "    specials=[\"<unk>\", \"<pad>\"],\n",
        "    special_first=True\n",
        ")\n",
        "\n",
        "vocab_spanish = build_vocab_from_iterator(\n",
        "    all_tokens_spanish,\n",
        "    min_freq=1,\n",
        "    specials=[\"<unk>\", \"<pad>\"],\n",
        "    special_first=True\n",
        ")\n",
        "\n",
        "print(vocab_english.get_itos())\n",
        "print(vocab_spanish.get_itos())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Afnj2BlAtcy",
        "outputId": "1b510e86-d118-400e-a4c3-ebbf48db7a16"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', 'the', ',', 'a', 'of', '.', 'to', 'in', 'and', \"'\", 'Sri', 'have', 'on', 'you', 'European', 'I', 'Lanka', 'Parliament', 'President', 'minute', 'number', 's', 'silence', 'that', 'this', 'Madam', 'You', 'as', 'be', 'countries', 'few', 'for', 'like', 'people', 'requested', 'session', 'very', 'will', \"'s\", '(', ')', '-', '17', '1999', '?', 'Although', 'December', 'Friday', 'House', 'In', 'Kumar', 'Lankan', 'Members', 'Mr', 'One', 'Please', 'Ponnambalam', 'The', 'Union', 'Would', 'adjourned', 'again', 'ago', 'all', 'appropriate', 'assassinated', 'at', 'aware', 'been', 'behalf', 'bomb', 'bug', 'can', 'concerned', 'course', 'days', 'deaths', 'debate', 'declare', 'difficult', 'disasters', 'do', 'dreaded', 'dreadful', 'during', 'enjoyed', 'everything', 'explosions', 'expressing', 'failed', 'festive', 'from', 'had', 'happy', 'her', 'his', 'hope', 'it', 'just', 'killings', 'letter', 'materialise', 'meantime', 'millennium', 'months', 'natural', 'new', 'next', 'observe', 'observed', 'once', 'order', 'other', 'part', 'particularly', 'peaceful', 'period', 'pleasant', 'point', 'possibly', 'press', 'recently', 'reconciliation', 'regret', 'resumed', 'rise', 'rose', 'seek', 'seen', 'series', 'she', 'should', 'situation', 'still', 'storms', 'subject', 'suffered', 'television', 'terrible', 'then', 'there', 'those', 'truly', 'urging', 'various', 'victims', 'violent', 'visited', 'was', 'were', 'who', 'wish', 'would', 'write', 'year']\n",
            "['<unk>', '<pad>', 'de', ',', 'que', '.', 'el', 'han', 'en', 'la', 'Parlamento', 'las', 'un', 'una', 'y', 'Lanka', 'Sri', 'a', 'del', 'los', 'minuto', 'para', 'se', 'silencio', '\"', 'Europeo', 'Presidenta', 'Señora', 'Señorías', 'Sus', 'al', 'ha', 'lo', 'países', 'período', 'pie', 'por', 'producido', 'sesiones', 'sido', 'todos', 'usted', 'víctimas', '(', ')', '17', '2000', '?', 'A', 'Como', 'Declaro', 'El', 'En', 'Europea', 'Invito', 'Kumar', 'Ponnambalam', 'Presidente', 'Sabrá', 'Sería', 'Sr.', 'Una', 'Unión', 'acuerdo', 'afectados', 'ante', 'apropiado', 'asesinado', 'asesinatos', 'año', 'buenas', 'cambio', 'carta', 'catástrofes', 'ciudadanos', 'colegas', 'comprobar', 'con', 'condolencias', 'cuestión', 'curso', 'debate', 'deseo', 'diciembre', 'difícil', 'distintos', 'días', 'efecto', 'encontrar', 'esa', 'escribiese', 'espera', 'este', 'está', 'explosiones', 'expresando', 'extremadamente', 'gran', 'guarda', 'guardar', 'hace', 'haga', 'hagamos', 'hayan', 'interrumpido', 'me', 'memoria', 'meses', 'mi', 'muchos', 'muertes', 'naturales', 'no', 'nos', 'nuestros', 'otras', 'pacífica', 'pasado', 'país', 'pedido', 'personas', 'pidiéndole', 'pido', 'pocos', 'podido', 'pongamos', 'posible', 'prensa', 'procedimiento', 'produzca', 'próximos', 'quien', 'reanudado', 'recientemente', 'reconciliación', 'reitero', 'serie', 'situación', 'sobre', 'solicitado', 'su', 'televisión', 'tema', 'tenido', 'terribles', 'todas', 'todo', 'tormentas', 'unas', 'vacaciones', 'varios', 'verdaderamente', 'viernes', 'violentas', 'visitó', 'viviendo', '¿']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Numericalize the all_tokens array\n",
        "def numericalize_and_pad(vocab, list_of_token_lists, sentence_size):\n",
        "  numericalized_unpadded = [vocab(tokens) for tokens in list_of_token_lists]\n",
        "  # For each sentence, subtract max size from size of that token and create array of size difference full of padding index\n",
        "  # Pad index is concatenated to numericalized sentence\n",
        "  # Return tensor full of numericalized and padded sentences\n",
        "  numericalized_sentences = []\n",
        "  for sentence in numericalized_unpadded:\n",
        "    if len(sentence) > sentence_size:\n",
        "      sentence = sentence[:sentence_size]\n",
        "      numericalized_sentences.append(sentence)\n",
        "    else:\n",
        "      padding_size = sentence_size - len(sentence)\n",
        "      padding = [vocab[\"<pad>\"] for _ in range(padding_size)]\n",
        "      sentence.extend(padding)\n",
        "      numericalized_sentences.append(sentence)\n",
        "\n",
        "\n",
        "  return torch.tensor(numericalized_sentences)\n",
        "\n",
        "print(numericalize_and_pad(vocab_english, all_tokens_english, 100)[0])\n",
        "print(numericalize_and_pad(vocab_english, all_tokens_english, 100).shape)\n",
        "\n",
        "print(numericalize_and_pad(vocab_spanish, all_tokens_spanish, 100)[0])\n",
        "print(numericalize_and_pad(vocab_spanish, all_tokens_spanish, 100).shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMTCHcL1JI95",
        "outputId": "b92c4b9d-91ae-4d6d-8de7-1c753f76b9b4"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 16,  79, 125,   2,  36,   5,   2,  15,  18,  61,  13,  48,  43,  47,\n",
            "         44,   3,   9,  16, 153,  33, 111,  62,   7, 152,  14,   4,  94, 107,\n",
            "        155,   8,   2,  97,  24,  14,  86,   4, 118,  91, 117,   6,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1])\n",
            "torch.Size([10, 100])\n",
            "tensor([ 50, 132,   6,  34,   2,  38,  18,  10,  25,   3, 104,   6, 152,  45,\n",
            "          2,  83, 117,   3,  14, 135,  17,  29,  28, 108,  82,   2,   4, 103,\n",
            "        143, 148,  70, 149,   5,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1])\n",
            "torch.Size([10, 100])\n"
          ]
        }
      ]
    }
  ]
}